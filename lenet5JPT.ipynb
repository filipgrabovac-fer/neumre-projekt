{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b60378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_ROOT = (PROJECT_ROOT.parent / \"data\").resolve()\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEFAULT_IMG_SIZE = 32\n",
    "PIN_MEMORY = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed()\n",
    "print(f\"Initialized notebook on {DEVICE} | data root: {DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f376b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transforms(img_size: int = DEFAULT_IMG_SIZE) -> transforms.Compose:\n",
    "    \"\"\"Standard Fashion-MNIST resizing + normalization.\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_train_loader(\n",
    "    batch_size: int = 256,\n",
    "    img_size: int = DEFAULT_IMG_SIZE,\n",
    "    num_workers: int = 2,\n",
    "    shuffle: bool = True,\n",
    ") -> DataLoader:\n",
    "    \"\"\"Return a loader over the Fashion-MNIST training split.\"\"\"\n",
    "    transform = build_transforms(img_size)\n",
    "    train_dataset = datasets.FashionMNIST(\n",
    "        root=DATA_ROOT,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform,\n",
    "    )\n",
    "    return DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def dataloader_to_numpy(loader: DataLoader, max_batches: int | None = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    xs, ys = [], []\n",
    "    for idx, (xb, yb) in enumerate(loader):\n",
    "        xs.append(xb.cpu().numpy())\n",
    "        ys.append(yb.cpu().numpy())\n",
    "        if max_batches is not None and idx + 1 >= max_batches:\n",
    "            break\n",
    "    return np.concatenate(xs, axis=0), np.concatenate(ys, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cedf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"Classic LeNet-5: 2 conv blocks (with AvgPool) followed by 3 fully connected layers.\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels: int = 1, num_classes: int = 10, img_size: int = DEFAULT_IMG_SIZE):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.conv1 = nn.Conv2d(input_channels, 6, kernel_size=5, stride=1, padding=0)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, input_channels, img_size, img_size)\n",
    "            features = self._forward_features(dummy)\n",
    "            flatten_dim = features.view(1, -1).shape[1]\n",
    "\n",
    "        self.fc1 = nn.Linear(flatten_dim, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def _forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._forward_features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23578d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Minimal sklearn wrapper used purely for hyper-parameter search.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_class=LeNet5,\n",
    "        model_kwargs=None,\n",
    "        lr: float = 1e-3,\n",
    "        batch_size: int = 64,\n",
    "        epochs: int = 5,\n",
    "        optimizer_name: str = \"adam\",\n",
    "        weight_decay: float = 0.0,\n",
    "        momentum: float = 0.9,\n",
    "        device: str | None = None,\n",
    "        seed: int = 42,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "        self.model_class = model_class\n",
    "        self.model_kwargs = model_kwargs or {\n",
    "            \"input_channels\": 1,\n",
    "            \"num_classes\": 10,\n",
    "            \"img_size\": DEFAULT_IMG_SIZE,\n",
    "        }\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.optimizer_name = optimizer_name\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum = momentum\n",
    "        self.device = device\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.model_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def _resolve_device(self):\n",
    "        if self.device is not None:\n",
    "            return torch.device(self.device)\n",
    "        return DEVICE\n",
    "\n",
    "    def _set_seed(self):\n",
    "        set_seed(self.seed)\n",
    "\n",
    "    def _make_optimizer(self, params):\n",
    "        name = self.optimizer_name.lower()\n",
    "        if name == \"adam\":\n",
    "            return torch.optim.Adam(params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "        if name == \"sgd\":\n",
    "            return torch.optim.SGD(params, lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
    "        raise ValueError(f\"Unknown optimizer {self.optimizer_name}\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._set_seed()\n",
    "        device = self._resolve_device()\n",
    "        X_t = torch.as_tensor(X, dtype=torch.float32)\n",
    "        y_t = torch.as_tensor(y, dtype=torch.long)\n",
    "        dataset = torch.utils.data.TensorDataset(X_t, y_t)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        self.model_ = self.model_class(**self.model_kwargs).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = self._make_optimizer(self.model_.parameters())\n",
    "        self.classes_ = np.unique(np.asarray(y))\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_loss = 0.0\n",
    "            total = 0\n",
    "            for xb, yb in loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                logits = self.model_(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += float(loss.item()) * xb.size(0)\n",
    "                total += xb.size(0)\n",
    "            if self.verbose:\n",
    "                print(f\"[TorchClassifier] epoch {epoch + 1}/{self.epochs} loss={epoch_loss/total:.4f}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.model_ is None:\n",
    "            raise RuntimeError(\"Call fit before predict.\")\n",
    "        device = self._resolve_device()\n",
    "        X_t = torch.as_tensor(X, dtype=torch.float32)\n",
    "        dataset = torch.utils.data.TensorDataset(X_t)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for (xb,) in loader:\n",
    "                logits = self.model_(xb.to(device))\n",
    "                preds.append(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "        return np.concatenate(preds, axis=0)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if self.model_ is None:\n",
    "            raise RuntimeError(\"Call fit before predict_proba.\")\n",
    "        device = self._resolve_device()\n",
    "        X_t = torch.as_tensor(X, dtype=torch.float32)\n",
    "        dataset = torch.utils.data.TensorDataset(X_t)\n",
    "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        probs = []\n",
    "        with torch.no_grad():\n",
    "            for (xb,) in loader:\n",
    "                logits = self.model_(xb.to(device))\n",
    "                probs.append(torch.softmax(logits, dim=1).cpu().numpy())\n",
    "        return np.concatenate(probs, axis=0)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return float((preds == np.asarray(y)).mean())\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"lr\": [1e-2, 5e-3, 1e-3, 5e-4],\n",
    "    \"batch_size\": [32, 64, 128, 256],\n",
    "    \"epochs\": [5, 10, 15],\n",
    "    \"optimizer_name\": [\"adam\", \"sgd\"],\n",
    "    \"weight_decay\": [0.0, 1e-4, 5e-4, 1e-3],\n",
    "}\n",
    "\n",
    "train_loader = get_train_loader(batch_size=256, img_size=DEFAULT_IMG_SIZE)\n",
    "X_train_sub, y_train_sub = dataloader_to_numpy(train_loader, max_batches=120)\n",
    "\n",
    "lenet_estimator = TorchClassifier(device=str(DEVICE))\n",
    "lenet_grid = GridSearchCV(lenet_estimator, param_grid=param_grid, cv=3, n_jobs=4, verbose=2)\n",
    "\n",
    "lenet_grid.fit(X_train_sub, y_train_sub)\n",
    "print(\"Best params:\", lenet_grid.best_params_)\n",
    "print(\"Best CV score:\", lenet_grid.best_score_)\n",
    "\n",
    "# Persist best model artifacts for later reuse\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "best_estimator = lenet_grid.best_estimator_\n",
    "best_model = best_estimator.model_\n",
    "weights_path = ARTIFACTS_DIR / \"lenet5_grid_best_weights.pt\"\n",
    "torch.save(best_model.state_dict(), weights_path)\n",
    "\n",
    "metadata = {\n",
    "    \"best_params\": lenet_grid.best_params_,\n",
    "    \"cv_score\": float(lenet_grid.best_score_),\n",
    "    \"model_kwargs\": best_estimator.model_kwargs,\n",
    "}\n",
    "params_path = ARTIFACTS_DIR / \"lenet5_grid_best_params.json\"\n",
    "with params_path.open(\"w\", encoding=\"utf-8\") as fh:\n",
    "    json.dump(metadata, fh, indent=2)\n",
    "\n",
    "estimator_path = ARTIFACTS_DIR / \"lenet5_grid_best_estimator.pt\"\n",
    "torch.save(best_estimator, estimator_path)\n",
    "print(f\"Saved weights to {weights_path}\")\n",
    "print(f\"Saved params to {params_path}\")\n",
    "print(f\"Saved sklearn wrapper to {estimator_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
