{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# LeNet-5 Evaluation on Fashion-MNIST\n",
    "\n",
    "Classic LeNet-5 architecture (1998) for baseline comparison:\n",
    "- 2 convolutional layers with average pooling\n",
    "- 3 fully connected layers\n",
    "- ~60K parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ed8bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bee4973",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.5],\n",
    "                                                          std=[0.5])\n",
    "                                     ])\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root = './data',\n",
    "                                             train = True,\n",
    "                                             transform = all_transforms,\n",
    "                                             download = True)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root = './data',\n",
    "                                            train = False,\n",
    "                                            transform = all_transforms,\n",
    "                                            download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6762588",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"Classic LeNet-5 architecture from 1998\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Input: 32x32 -> conv1: 28x28 -> pool: 14x14 -> conv2: 10x10 -> pool: 5x5\n",
    "        # Flattened size: 16 * 5 * 5 = 400\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First conv block with tanh activation (original LeNet used tanh)\n",
    "        out = torch.tanh(self.conv1(x))\n",
    "        out = self.avgpool1(out)\n",
    "        \n",
    "        # Second conv block\n",
    "        out = torch.tanh(self.conv2(out))\n",
    "        out = self.avgpool2(out)\n",
    "        \n",
    "        # Flatten\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = torch.tanh(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5e292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 61,706\n"
     ]
    }
   ],
   "source": [
    "model = LeNet5(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07640ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.0510\n",
      "Epoch [2/20], Loss: 0.6688\n",
      "Epoch [3/20], Loss: 0.5379\n",
      "Epoch [4/20], Loss: 0.6628\n",
      "Epoch [5/20], Loss: 0.7042\n",
      "Epoch [6/20], Loss: 0.7732\n",
      "Epoch [7/20], Loss: 0.5343\n",
      "Epoch [8/20], Loss: 0.6167\n",
      "Epoch [9/20], Loss: 0.7109\n",
      "Epoch [10/20], Loss: 0.6341\n",
      "Epoch [11/20], Loss: 0.2118\n",
      "Epoch [12/20], Loss: 0.2745\n",
      "Epoch [13/20], Loss: 0.3669\n",
      "Epoch [14/20], Loss: 0.4451\n",
      "Epoch [15/20], Loss: 0.3616\n",
      "Epoch [16/20], Loss: 0.4710\n",
      "Epoch [17/20], Loss: 0.2176\n",
      "Epoch [18/20], Loss: 0.3557\n",
      "Epoch [19/20], Loss: 0.3381\n",
      "Epoch [20/20], Loss: 0.5895\n"
     ]
    }
   ],
   "source": [
    "# Initial training run to test the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9188e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83.91 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Accuracy of the network on the {} test images: {:.2f} %'.format(10000, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ptwobrs26kc",
   "metadata": {},
   "source": [
    "## Grid Search for Hyperparameter Tuning\n",
    "\n",
    "Testing different combinations of:\n",
    "- Optimizers: SGD, Adam\n",
    "- Learning rates: 0.001, 0.01, 0.1\n",
    "- Weight decay: 0, 0.005\n",
    "\n",
    "Total configurations: 2 × 3 × 2 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "so6flxmeptn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations to test: 12\n"
     ]
    }
   ],
   "source": [
    "# Grid search hyperparameters\n",
    "optimizers_to_test = ['sgd', 'adam']\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "weight_decays = [0, 0.005]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "print(f\"Total configurations to test: {len(optimizers_to_test) * len(learning_rates) * len(weight_decays)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "z1j8ni5vbi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Configuration 1/12\n",
      "Optimizer: sgd, LR: 0.001, Weight Decay: 0\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.4220\n",
      "  Epoch [10/20], Loss: 0.3296\n",
      "  Epoch [15/20], Loss: 0.5577\n",
      "  Epoch [20/20], Loss: 0.6093\n",
      "  Test Accuracy: 86.26%\n",
      "  Training Time: 91.79s\n",
      "\n",
      "============================================================\n",
      "Configuration 2/12\n",
      "Optimizer: sgd, LR: 0.001, Weight Decay: 0.005\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.5239\n",
      "  Epoch [10/20], Loss: 0.4589\n",
      "  Epoch [15/20], Loss: 0.5131\n",
      "  Epoch [20/20], Loss: 0.4805\n",
      "  Test Accuracy: 84.43%\n",
      "  Training Time: 92.16s\n",
      "\n",
      "============================================================\n",
      "Configuration 3/12\n",
      "Optimizer: sgd, LR: 0.01, Weight Decay: 0\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.3436\n",
      "  Epoch [10/20], Loss: 0.3595\n",
      "  Epoch [15/20], Loss: 0.2057\n",
      "  Epoch [20/20], Loss: 0.3170\n",
      "  Test Accuracy: 89.95%\n",
      "  Training Time: 91.45s\n",
      "\n",
      "============================================================\n",
      "Configuration 4/12\n",
      "Optimizer: sgd, LR: 0.01, Weight Decay: 0.005\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.7747\n",
      "  Epoch [10/20], Loss: 0.1770\n",
      "  Epoch [15/20], Loss: 0.2289\n",
      "  Epoch [20/20], Loss: 0.5715\n",
      "  Test Accuracy: 85.71%\n",
      "  Training Time: 91.58s\n",
      "\n",
      "============================================================\n",
      "Configuration 5/12\n",
      "Optimizer: sgd, LR: 0.1, Weight Decay: 0\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.2895\n",
      "  Epoch [10/20], Loss: 0.3210\n",
      "  Epoch [15/20], Loss: 0.3475\n",
      "  Epoch [20/20], Loss: 0.5215\n",
      "  Test Accuracy: 85.98%\n",
      "  Training Time: 91.61s\n",
      "\n",
      "============================================================\n",
      "Configuration 6/12\n",
      "Optimizer: sgd, LR: 0.1, Weight Decay: 0.005\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.6411\n",
      "  Epoch [10/20], Loss: 0.4960\n",
      "  Epoch [15/20], Loss: 0.6800\n",
      "  Epoch [20/20], Loss: 0.9086\n",
      "  Test Accuracy: 78.95%\n",
      "  Training Time: 91.97s\n",
      "\n",
      "============================================================\n",
      "Configuration 7/12\n",
      "Optimizer: adam, LR: 0.001, Weight Decay: 0\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.4483\n",
      "  Epoch [10/20], Loss: 0.1425\n",
      "  Epoch [15/20], Loss: 0.2131\n",
      "  Epoch [20/20], Loss: 0.1964\n",
      "  Test Accuracy: 89.14%\n",
      "  Training Time: 92.62s\n",
      "\n",
      "============================================================\n",
      "Configuration 8/12\n",
      "Optimizer: adam, LR: 0.001, Weight Decay: 0.005\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.8662\n",
      "  Epoch [10/20], Loss: 0.3987\n",
      "  Epoch [15/20], Loss: 0.6263\n",
      "  Epoch [20/20], Loss: 0.3134\n",
      "  Test Accuracy: 85.18%\n",
      "  Training Time: 93.66s\n",
      "\n",
      "============================================================\n",
      "Configuration 9/12\n",
      "Optimizer: adam, LR: 0.01, Weight Decay: 0\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.3355\n",
      "  Epoch [10/20], Loss: 0.3327\n",
      "  Epoch [15/20], Loss: 0.4674\n",
      "  Epoch [20/20], Loss: 0.5055\n",
      "  Test Accuracy: 77.16%\n",
      "  Training Time: 92.89s\n",
      "\n",
      "============================================================\n",
      "Configuration 10/12\n",
      "Optimizer: adam, LR: 0.01, Weight Decay: 0.005\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 0.5652\n",
      "  Epoch [10/20], Loss: 0.4794\n",
      "  Epoch [15/20], Loss: 0.7127\n",
      "  Epoch [20/20], Loss: 0.6755\n",
      "  Test Accuracy: 79.86%\n",
      "  Training Time: 93.17s\n",
      "\n",
      "============================================================\n",
      "Configuration 11/12\n",
      "Optimizer: adam, LR: 0.1, Weight Decay: 0\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 1.6637\n",
      "  Epoch [10/20], Loss: 2.0847\n",
      "  Epoch [15/20], Loss: 1.5241\n",
      "  Epoch [20/20], Loss: 1.2334\n",
      "  Test Accuracy: 51.26%\n",
      "  Training Time: 93.05s\n",
      "\n",
      "============================================================\n",
      "Configuration 12/12\n",
      "Optimizer: adam, LR: 0.1, Weight Decay: 0.005\n",
      "============================================================\n",
      "  Epoch [5/20], Loss: 1.3316\n",
      "  Epoch [10/20], Loss: 1.6066\n",
      "  Epoch [15/20], Loss: 1.5372\n",
      "  Epoch [20/20], Loss: 1.4138\n",
      "  Test Accuracy: 43.66%\n",
      "  Training Time: 93.31s\n",
      "\n",
      "============================================================\n",
      "Grid search completed!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "config_num = 0\n",
    "for optimizer_name in optimizers_to_test:\n",
    "    for lr in learning_rates:\n",
    "        for wd in weight_decays:\n",
    "            config_num += 1\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Configuration {config_num}/12\")\n",
    "            print(f\"Optimizer: {optimizer_name}, LR: {lr}, Weight Decay: {wd}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            # Create fresh model\n",
    "            model = LeNet5(num_classes).to(device)\n",
    "            \n",
    "            # Create optimizer based on type\n",
    "            if optimizer_name == 'sgd':\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
    "            else:  # adam\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Training\n",
    "            start_time = time.time()\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                for i, (images, labels) in enumerate(train_loader):\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                if (epoch + 1) % 5 == 0:  # Print every 5 epochs\n",
    "                    print(f'  Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Evaluation on test set\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                test_accuracy = 100 * correct / total\n",
    "            \n",
    "            print(f\"  Test Accuracy: {test_accuracy:.2f}%\")\n",
    "            print(f\"  Training Time: {training_time:.2f}s\")\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'optimizer': optimizer_name,\n",
    "                'learning_rate': lr,\n",
    "                'weight_decay': wd,\n",
    "                'test_accuracy': test_accuracy,\n",
    "                'training_time': training_time\n",
    "            })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Grid search completed!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7h2s1cjlwe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GRID SEARCH RESULTS - Sorted by Test Accuracy\n",
      "================================================================================\n",
      "Rank   Optimizer  LR         Weight Decay  Test Acc     Time (s)  \n",
      "--------------------------------------------------------------------------------\n",
      "1      sgd        0.01       0             89.95        91.45     \n",
      "2      adam       0.001      0             89.14        92.62     \n",
      "3      sgd        0.001      0             86.26        91.79     \n",
      "4      sgd        0.1        0             85.98        91.61     \n",
      "5      sgd        0.01       0.005         85.71        91.58     \n",
      "6      adam       0.001      0.005         85.18        93.66     \n",
      "7      sgd        0.001      0.005         84.43        92.16     \n",
      "8      adam       0.01       0.005         79.86        93.17     \n",
      "9      sgd        0.1        0.005         78.95        91.97     \n",
      "10     adam       0.01       0             77.16        92.89     \n",
      "11     adam       0.1        0             51.26        93.05     \n",
      "12     adam       0.1        0.005         43.66        93.31     \n",
      "================================================================================\n",
      "\n",
      "BEST CONFIGURATION:\n",
      "  Optimizer: sgd\n",
      "  Learning Rate: 0.01\n",
      "  Weight Decay: 0\n",
      "  Test Accuracy: 89.95%\n",
      "  Training Time: 91.45s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display all results sorted by test accuracy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRID SEARCH RESULTS - Sorted by Test Accuracy\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Rank':<6} {'Optimizer':<10} {'LR':<10} {'Weight Decay':<13} {'Test Acc':<12} {'Time (s)':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Sort results by test accuracy (descending)\n",
    "sorted_results = sorted(results, key=lambda x: x['test_accuracy'], reverse=True)\n",
    "\n",
    "for rank, result in enumerate(sorted_results, 1):\n",
    "    print(f\"{rank:<6} {result['optimizer']:<10} {result['learning_rate']:<10} \"\n",
    "          f\"{result['weight_decay']:<13} {result['test_accuracy']:<12.2f} {result['training_time']:<10.2f}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"\\nBEST CONFIGURATION:\")\n",
    "best = sorted_results[0]\n",
    "print(f\"  Optimizer: {best['optimizer']}\")\n",
    "print(f\"  Learning Rate: {best['learning_rate']}\")\n",
    "print(f\"  Weight Decay: {best['weight_decay']}\")\n",
    "print(f\"  Test Accuracy: {best['test_accuracy']:.2f}%\")\n",
    "print(f\"  Training Time: {best['training_time']:.2f}s\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bv7r1xindh",
   "metadata": {},
   "source": [
    "## Retrain Best Configuration and Save Model\n",
    "\n",
    "Retraining the best configuration and saving the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nty1puqmg0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with best configuration...\n",
      "Optimizer: sgd, LR: 0.01, Weight Decay: 0\n",
      "\n",
      "Epoch [5/20], Loss: 0.2495\n",
      "Epoch [10/20], Loss: 0.3509\n",
      "Epoch [15/20], Loss: 0.3547\n",
      "Epoch [20/20], Loss: 0.0842\n",
      "\n",
      "Model saved to 'best_lenet5_model.pth'\n",
      "Final Test Accuracy: 89.91%\n"
     ]
    }
   ],
   "source": [
    "# Best configuration from grid search\n",
    "best_optimizer = best['optimizer']\n",
    "best_lr = best['learning_rate']\n",
    "best_wd = best['weight_decay']\n",
    "\n",
    "print(\"Training with best configuration...\")\n",
    "print(f\"Optimizer: {best_optimizer}, LR: {best_lr}, Weight Decay: {best_wd}\\n\")\n",
    "\n",
    "# Create fresh model\n",
    "best_model = LeNet5(num_classes).to(device)\n",
    "\n",
    "# Create optimizer\n",
    "if best_optimizer == 'sgd':\n",
    "    optimizer = torch.optim.SGD(best_model.parameters(), lr=best_lr, weight_decay=best_wd, momentum=0.9)\n",
    "else:  # adam\n",
    "    optimizer = torch.optim.Adam(best_model.parameters(), lr=best_lr, weight_decay=best_wd)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    best_model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = best_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model.state_dict(), 'best_lenet5_model.pth')\n",
    "print(f\"\\nModel saved to 'best_lenet5_model.pth'\")\n",
    "\n",
    "# Final evaluation\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = best_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    final_accuracy = 100 * correct / total\n",
    "    print(f'Final Test Accuracy: {final_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## Comparison Notes\n",
    "\n",
    "**LeNet-5 (1998)** vs **Custom CNN (2020s)**\n",
    "\n",
    "Architecture differences:\n",
    "- LeNet: 2 conv layers with AvgPool, tanh activation, ~60K params\n",
    "- Custom CNN: 4 conv layers with MaxPool, ReLU activation, ~1M params\n",
    "\n",
    "Expected results:\n",
    "- LeNet-5: ~87-89% accuracy (classic baseline)\n",
    "- Custom CNN: ~90%+ accuracy (modern improvements)\n",
    "\n",
    "This demonstrates the impact of architectural evolution over 25+ years."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neumre-projekt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
